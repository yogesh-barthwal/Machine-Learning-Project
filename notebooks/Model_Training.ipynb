{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "9ce6f7d4",
   "metadata": {},
   "source": [
    "### Objective- To predict the quality of wine on a scale of 1-10 (bad----good)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bfa9e1d3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importing the basic libraries\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import seaborn as sns\n",
    "    # For Model building and its evaluation\n",
    "from sklearn.model_selection import train_test_split, GridSearchCV\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.preprocessing import StandardScaler\n",
    "from sklearn.metrics import accuracy_score, recall_score,confusion_matrix, ConfusionMatrixDisplay, classification_report, precision_score,roc_auc_score\n",
    "from statsmodels.stats.outliers_influence import variance_inflation_factor\n",
    "from sklearn import metrics\n",
    "from sklearn.preprocessing import LabelEncoder\n",
    "from sklearn.preprocessing import RobustScaler\n",
    "from sklearn.linear_model import LogisticRegression\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.neighbors import KNeighborsClassifier\n",
    "from sklearn.svm import SVC\n",
    "from sklearn.naive_bayes import GaussianNB\n",
    "from sklearn.model_selection import cross_val_score\n",
    "    # To supress warnings\n",
    "from sklearn.exceptions import ConvergenceWarning\n",
    "ConvergenceWarning('ignore')\n",
    "import warnings\n",
    "warnings.filterwarnings('ignore')\n",
    "# For Pipeline\n",
    "from sklearn.preprocessing import FunctionTransformer\n",
    "from sklearn.compose import ColumnTransformer\n",
    "from sklearn.pipeline import Pipeline"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "5ddd9e2d",
   "metadata": {},
   "outputs": [],
   "source": [
    "df= pd.read_csv(r\"Y:\\Data\\Projects\\Machine Learning Project\\notebooks\\data\\QualityPrediction.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "68283918",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Creating a copy of raw data\n",
    "df_raw= df.copy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "6082f082",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.70         0.00             1.9      0.076   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head(5)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c3642565",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<class 'pandas.core.frame.DataFrame'>\n",
      "RangeIndex: 1599 entries, 0 to 1598\n",
      "Data columns (total 12 columns):\n",
      " #   Column                Non-Null Count  Dtype  \n",
      "---  ------                --------------  -----  \n",
      " 0   fixed acidity         1599 non-null   float64\n",
      " 1   volatile acidity      1599 non-null   float64\n",
      " 2   citric acid           1599 non-null   float64\n",
      " 3   residual sugar        1599 non-null   float64\n",
      " 4   chlorides             1599 non-null   float64\n",
      " 5   free sulfur dioxide   1599 non-null   float64\n",
      " 6   total sulfur dioxide  1599 non-null   float64\n",
      " 7   density               1599 non-null   float64\n",
      " 8   pH                    1599 non-null   float64\n",
      " 9   sulphates             1599 non-null   float64\n",
      " 10  alcohol               1599 non-null   float64\n",
      " 11  quality               1599 non-null   int64  \n",
      "dtypes: float64(11), int64(1)\n",
      "memory usage: 150.0 KB\n"
     ]
    }
   ],
   "source": [
    "df.info()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8b753868",
   "metadata": {},
   "source": [
    "#### Observations-\n",
    "All the variables are numerical in nature"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e381387a",
   "metadata": {},
   "source": [
    "Checking for duplicate values\n",
    "\n",
    "- Duplicate observations will not provide any additional information to the model and hence should be dropped\n",
    "- Further, when the dataset will be split into training and test dataset, exactly same observation values may end up being in both. This may result in overfitting"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "id": "5056591c",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "240\n"
     ]
    }
   ],
   "source": [
    "print(df.duplicated().sum())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "82aa54e9",
   "metadata": {},
   "source": [
    "There are a total of 240 duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 115,
   "id": "a77ddc03",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.700</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.90</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>11</th>\n",
       "      <td>7.5</td>\n",
       "      <td>0.500</td>\n",
       "      <td>0.36</td>\n",
       "      <td>6.10</td>\n",
       "      <td>0.071</td>\n",
       "      <td>17.0</td>\n",
       "      <td>102.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.35</td>\n",
       "      <td>0.80</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>27</th>\n",
       "      <td>7.9</td>\n",
       "      <td>0.430</td>\n",
       "      <td>0.21</td>\n",
       "      <td>1.60</td>\n",
       "      <td>0.106</td>\n",
       "      <td>10.0</td>\n",
       "      <td>37.0</td>\n",
       "      <td>0.99660</td>\n",
       "      <td>3.17</td>\n",
       "      <td>0.91</td>\n",
       "      <td>9.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>40</th>\n",
       "      <td>7.3</td>\n",
       "      <td>0.450</td>\n",
       "      <td>0.36</td>\n",
       "      <td>5.90</td>\n",
       "      <td>0.074</td>\n",
       "      <td>12.0</td>\n",
       "      <td>87.0</td>\n",
       "      <td>0.99780</td>\n",
       "      <td>3.33</td>\n",
       "      <td>0.83</td>\n",
       "      <td>10.5</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>65</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.725</td>\n",
       "      <td>0.05</td>\n",
       "      <td>4.65</td>\n",
       "      <td>0.086</td>\n",
       "      <td>4.0</td>\n",
       "      <td>11.0</td>\n",
       "      <td>0.99620</td>\n",
       "      <td>3.41</td>\n",
       "      <td>0.39</td>\n",
       "      <td>10.9</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1563</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.076</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.99546</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1564</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.076</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.99546</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1567</th>\n",
       "      <td>7.2</td>\n",
       "      <td>0.695</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.00</td>\n",
       "      <td>0.076</td>\n",
       "      <td>12.0</td>\n",
       "      <td>20.0</td>\n",
       "      <td>0.99546</td>\n",
       "      <td>3.29</td>\n",
       "      <td>0.54</td>\n",
       "      <td>10.1</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1581</th>\n",
       "      <td>6.2</td>\n",
       "      <td>0.560</td>\n",
       "      <td>0.09</td>\n",
       "      <td>1.70</td>\n",
       "      <td>0.053</td>\n",
       "      <td>24.0</td>\n",
       "      <td>32.0</td>\n",
       "      <td>0.99402</td>\n",
       "      <td>3.54</td>\n",
       "      <td>0.60</td>\n",
       "      <td>11.3</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1596</th>\n",
       "      <td>6.3</td>\n",
       "      <td>0.510</td>\n",
       "      <td>0.13</td>\n",
       "      <td>2.30</td>\n",
       "      <td>0.076</td>\n",
       "      <td>29.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.99574</td>\n",
       "      <td>3.42</td>\n",
       "      <td>0.75</td>\n",
       "      <td>11.0</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>240 rows Ã— 12 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "4               7.4             0.700         0.00            1.90      0.076   \n",
       "11              7.5             0.500         0.36            6.10      0.071   \n",
       "27              7.9             0.430         0.21            1.60      0.106   \n",
       "40              7.3             0.450         0.36            5.90      0.074   \n",
       "65              7.2             0.725         0.05            4.65      0.086   \n",
       "...             ...               ...          ...             ...        ...   \n",
       "1563            7.2             0.695         0.13            2.00      0.076   \n",
       "1564            7.2             0.695         0.13            2.00      0.076   \n",
       "1567            7.2             0.695         0.13            2.00      0.076   \n",
       "1581            6.2             0.560         0.09            1.70      0.053   \n",
       "1596            6.3             0.510         0.13            2.30      0.076   \n",
       "\n",
       "      free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "4                    11.0                  34.0  0.99780  3.51       0.56   \n",
       "11                   17.0                 102.0  0.99780  3.35       0.80   \n",
       "27                   10.0                  37.0  0.99660  3.17       0.91   \n",
       "40                   12.0                  87.0  0.99780  3.33       0.83   \n",
       "65                    4.0                  11.0  0.99620  3.41       0.39   \n",
       "...                   ...                   ...      ...   ...        ...   \n",
       "1563                 12.0                  20.0  0.99546  3.29       0.54   \n",
       "1564                 12.0                  20.0  0.99546  3.29       0.54   \n",
       "1567                 12.0                  20.0  0.99546  3.29       0.54   \n",
       "1581                 24.0                  32.0  0.99402  3.54       0.60   \n",
       "1596                 29.0                  40.0  0.99574  3.42       0.75   \n",
       "\n",
       "      alcohol  quality  \n",
       "4         9.4        5  \n",
       "11       10.5        5  \n",
       "27        9.5        5  \n",
       "40       10.5        5  \n",
       "65       10.9        5  \n",
       "...       ...      ...  \n",
       "1563     10.1        5  \n",
       "1564     10.1        5  \n",
       "1567     10.1        5  \n",
       "1581     11.3        5  \n",
       "1596     11.0        6  \n",
       "\n",
       "[240 rows x 12 columns]"
      ]
     },
     "execution_count": 115,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df[df.duplicated()]"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f97d0dbc",
   "metadata": {},
   "source": [
    "Removing the duplicate entries"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 116,
   "id": "6c1b4f8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.drop_duplicates(keep='first', inplace = True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 117,
   "id": "096cf649",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1359, 12)"
      ]
     },
     "execution_count": 117,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d3d52f2c",
   "metadata": {},
   "source": [
    "Now there are a total of 1359 observations and 12 columns (12 features and 1 target variable)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 118,
   "id": "36ef0fa2",
   "metadata": {},
   "outputs": [],
   "source": [
    "df.reset_index(drop=True, inplace=True ) # drop = True to avoid creating a new column"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 119,
   "id": "19e43c92",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>fixed acidity</th>\n",
       "      <th>volatile acidity</th>\n",
       "      <th>citric acid</th>\n",
       "      <th>residual sugar</th>\n",
       "      <th>chlorides</th>\n",
       "      <th>free sulfur dioxide</th>\n",
       "      <th>total sulfur dioxide</th>\n",
       "      <th>density</th>\n",
       "      <th>pH</th>\n",
       "      <th>sulphates</th>\n",
       "      <th>alcohol</th>\n",
       "      <th>quality</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.70</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.076</td>\n",
       "      <td>11.0</td>\n",
       "      <td>34.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.88</td>\n",
       "      <td>0.00</td>\n",
       "      <td>2.6</td>\n",
       "      <td>0.098</td>\n",
       "      <td>25.0</td>\n",
       "      <td>67.0</td>\n",
       "      <td>0.9968</td>\n",
       "      <td>3.20</td>\n",
       "      <td>0.68</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>7.8</td>\n",
       "      <td>0.76</td>\n",
       "      <td>0.04</td>\n",
       "      <td>2.3</td>\n",
       "      <td>0.092</td>\n",
       "      <td>15.0</td>\n",
       "      <td>54.0</td>\n",
       "      <td>0.9970</td>\n",
       "      <td>3.26</td>\n",
       "      <td>0.65</td>\n",
       "      <td>9.8</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>11.2</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.56</td>\n",
       "      <td>1.9</td>\n",
       "      <td>0.075</td>\n",
       "      <td>17.0</td>\n",
       "      <td>60.0</td>\n",
       "      <td>0.9980</td>\n",
       "      <td>3.16</td>\n",
       "      <td>0.58</td>\n",
       "      <td>9.8</td>\n",
       "      <td>6</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>7.4</td>\n",
       "      <td>0.66</td>\n",
       "      <td>0.00</td>\n",
       "      <td>1.8</td>\n",
       "      <td>0.075</td>\n",
       "      <td>13.0</td>\n",
       "      <td>40.0</td>\n",
       "      <td>0.9978</td>\n",
       "      <td>3.51</td>\n",
       "      <td>0.56</td>\n",
       "      <td>9.4</td>\n",
       "      <td>5</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "   fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       "0            7.4              0.70         0.00             1.9      0.076   \n",
       "1            7.8              0.88         0.00             2.6      0.098   \n",
       "2            7.8              0.76         0.04             2.3      0.092   \n",
       "3           11.2              0.28         0.56             1.9      0.075   \n",
       "4            7.4              0.66         0.00             1.8      0.075   \n",
       "\n",
       "   free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       "0                 11.0                  34.0   0.9978  3.51       0.56   \n",
       "1                 25.0                  67.0   0.9968  3.20       0.68   \n",
       "2                 15.0                  54.0   0.9970  3.26       0.65   \n",
       "3                 17.0                  60.0   0.9980  3.16       0.58   \n",
       "4                 13.0                  40.0   0.9978  3.51       0.56   \n",
       "\n",
       "   alcohol  quality  \n",
       "0      9.4        5  \n",
       "1      9.8        5  \n",
       "2      9.8        5  \n",
       "3      9.8        6  \n",
       "4      9.4        5  "
      ]
     },
     "execution_count": 119,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.head()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "70e3b7c6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['fixed acidity', 'volatile acidity', 'citric acid', 'residual sugar',\n",
       "       'chlorides', 'free sulfur dioxide', 'total sulfur dioxide', 'density',\n",
       "       'pH', 'sulphates', 'alcohol', 'quality'],\n",
       "      dtype='object')"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e8557d5d",
   "metadata": {},
   "source": [
    "Log transformation is one of the methods to reduce skewness, (specially right skewed) (achieve normal distribution) and handle outliers.\n",
    "\n",
    "It is especially helpful for models assuming normal distribution like linear regression\n",
    "\n",
    "Trying to the transform the skewed featues of dataset here too (for logistic regression) to handle skewness and outliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "836cd163",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_df = np.log1p(df.drop(['quality', 'pH', 'density'], axis=1)) # Transformation makes sense only for numerical features that are skewed(especially right skewed).\n",
    "#                                                                 Thus removing the categorical feature which happens to be the target variale and the only categorical variable"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 122,
   "id": "2413a0f6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_df = pd.concat([transformed_df,df[['pH', 'density','quality']]],axis=1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49e61c22",
   "metadata": {},
   "source": [
    "**This will be the first step of preprocessing that will be used in transformer**\n",
    "\n",
    "**But, instead of dropping the columns on which transformation is not to  be applied, we need to mention the columns on which transformation is to  be applied**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 123,
   "id": "abe244d6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['fixed acidity',\n",
       " 'volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'free sulfur dioxide',\n",
       " 'total sulfur dioxide',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 123,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "col_for_log_trans= df.columns.drop(['density', 'pH', 'quality']).tolist()\n",
    "col_for_log_trans"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 124,
   "id": "958764d0",
   "metadata": {},
   "outputs": [],
   "source": [
    "log_transformation= FunctionTransformer(func= np.log1p, feature_names_out='one-to-one')\n",
    "# feature_names_out='one-to-one': tells scikit-learn to retain column names"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 125,
   "id": "bf68860b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 126,
   "id": "dbe05856",
   "metadata": {},
   "outputs": [],
   "source": [
    "# transformed_df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d64f3279",
   "metadata": {},
   "source": [
    "#### Observations\n",
    "- \"fixed acidity\" has moderate correlation with a lot of features- \"citric acid\", \"density\" and \"pH\"\n",
    "- \"free sulfur dioxide\" and \"total sulfur oxide\" also have a moderate correaltion\n",
    "- These correaltions become stronger for the transformed data(except between \"citric acid\" and fixed \"acidity\")\n",
    "- We can check for VIF values too (after scaling) "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c65e645f",
   "metadata": {},
   "source": [
    "Dropping the features \"fixed acidity\" and \" free sulfur dioxide\" owing to multicollinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 127,
   "id": "70c15e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# df.drop(['fixed acidity', 'free sulfur dioxide'],axis=1,inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0e8304ab",
   "metadata": {},
   "source": [
    "**Second step for Transformation**\n",
    "\n",
    "**Selected columns will be used for transformation while remainder will be dropped as remainder='drop**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "420efc6a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "['volatile acidity',\n",
       " 'citric acid',\n",
       " 'residual sugar',\n",
       " 'chlorides',\n",
       " 'total sulfur dioxide',\n",
       " 'density',\n",
       " 'pH',\n",
       " 'sulphates',\n",
       " 'alcohol']"
      ]
     },
     "execution_count": 128,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "required_col= [col for col in df.columns if col not in['fixed acidity', 'free sulfur dioxide', 'quality']]\n",
    "required_col"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0506ca12",
   "metadata": {},
   "source": [
    "## Model Creation"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c3e3ca6e",
   "metadata": {},
   "source": [
    "Models will be created based on the following algorithms-\n",
    "- Logistic Regression on original data\n",
    "- Decision Tree\n",
    "- Random Forest\n",
    "- K Nearest Neighbours\n",
    "- Naive Bayes\n",
    "- Support Vector Machine\n",
    "- Logistic Regression on transformed data\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fd06c261",
   "metadata": {},
   "source": [
    "#### Creating independent and dependent variables"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 129,
   "id": "f6744dbf",
   "metadata": {},
   "outputs": [],
   "source": [
    "x= df.drop('quality',axis=1) # Independent variable to be used for all models\n",
    "y=df.quality # Target (dependent) variable to be used for all models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 130,
   "id": "515ecca9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(      fixed acidity  volatile acidity  citric acid  residual sugar  chlorides  \\\n",
       " 0               7.4             0.700         0.00             1.9      0.076   \n",
       " 1               7.8             0.880         0.00             2.6      0.098   \n",
       " 2               7.8             0.760         0.04             2.3      0.092   \n",
       " 3              11.2             0.280         0.56             1.9      0.075   \n",
       " 4               7.4             0.660         0.00             1.8      0.075   \n",
       " ...             ...               ...          ...             ...        ...   \n",
       " 1354            6.8             0.620         0.08             1.9      0.068   \n",
       " 1355            6.2             0.600         0.08             2.0      0.090   \n",
       " 1356            5.9             0.550         0.10             2.2      0.062   \n",
       " 1357            5.9             0.645         0.12             2.0      0.075   \n",
       " 1358            6.0             0.310         0.47             3.6      0.067   \n",
       " \n",
       "       free sulfur dioxide  total sulfur dioxide  density    pH  sulphates  \\\n",
       " 0                    11.0                  34.0  0.99780  3.51       0.56   \n",
       " 1                    25.0                  67.0  0.99680  3.20       0.68   \n",
       " 2                    15.0                  54.0  0.99700  3.26       0.65   \n",
       " 3                    17.0                  60.0  0.99800  3.16       0.58   \n",
       " 4                    13.0                  40.0  0.99780  3.51       0.56   \n",
       " ...                   ...                   ...      ...   ...        ...   \n",
       " 1354                 28.0                  38.0  0.99651  3.42       0.82   \n",
       " 1355                 32.0                  44.0  0.99490  3.45       0.58   \n",
       " 1356                 39.0                  51.0  0.99512  3.52       0.76   \n",
       " 1357                 32.0                  44.0  0.99547  3.57       0.71   \n",
       " 1358                 18.0                  42.0  0.99549  3.39       0.66   \n",
       " \n",
       "       alcohol  \n",
       " 0         9.4  \n",
       " 1         9.8  \n",
       " 2         9.8  \n",
       " 3         9.8  \n",
       " 4         9.4  \n",
       " ...       ...  \n",
       " 1354      9.5  \n",
       " 1355     10.5  \n",
       " 1356     11.2  \n",
       " 1357     10.2  \n",
       " 1358     11.0  \n",
       " \n",
       " [1359 rows x 11 columns],\n",
       " 0       5\n",
       " 1       5\n",
       " 2       5\n",
       " 3       6\n",
       " 4       5\n",
       "        ..\n",
       " 1354    6\n",
       " 1355    5\n",
       " 1356    6\n",
       " 1357    5\n",
       " 1358    6\n",
       " Name: quality, Length: 1359, dtype: int64)"
      ]
     },
     "execution_count": 130,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x,y"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "396b5ec7",
   "metadata": {},
   "source": [
    "#### Splitting the data into training and testing data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 131,
   "id": "3fba7cb1",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_train, x_test, y_train, y_test = train_test_split(x,y,test_size=.2,random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 132,
   "id": "34939323",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "((1087, 11), (272, 11), (1087,), (272,))"
      ]
     },
     "execution_count": 132,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "x_train.shape,x_test.shape, y_train.shape, y_test.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "50890c96",
   "metadata": {},
   "source": [
    "**The third step for transformer**"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7762aeb9",
   "metadata": {},
   "source": [
    "#### Feature Scaling"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "805b8104",
   "metadata": {},
   "source": [
    "#### Preprocessing before feeding into the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "53070b1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For distance based models\n",
    "preprocessor_scale= ColumnTransformer(transformers=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log transformation', log_transformation, col_for_log_trans),\n",
    "    ('scaling', StandardScaler(), required_col)\n",
    "],remainder='drop') # Dropping  rest of columns owing to multi collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4048d99b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# For non distance based models\n",
    "preprocessor_not_scale= ColumnTransformer(transformers=[\n",
    "    ('imputer', SimpleImputer(strategy='median')),\n",
    "    ('log transformation', log_transformation, col_for_log_trans),\n",
    "],remainder='drop') # Dropping  rest of columns owing to multi collinearity"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 135,
   "id": "5a3b7f7c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[ 2.29253476,  0.3220835 ,  0.33647224, ..., -0.25982192,\n",
       "         0.51985077,  1.98424001],\n",
       "       [ 2.02814825,  0.53062825,  0.07696104, ...,  0.85726724,\n",
       "        -0.45848943, -0.2158671 ],\n",
       "       [ 2.05412373,  0.44468582,  0.0295588 , ...,  0.85726724,\n",
       "        -0.17074231, -0.39920936],\n",
       "       ...,\n",
       "       [ 2.05412373,  0.3852624 ,  0.07696104, ..., -0.06268854,\n",
       "        -0.05564346, -0.76589387],\n",
       "       [ 2.29253476,  0.27763174,  0.27002714, ..., -0.91693319,\n",
       "        -0.6311377 , -0.03252484],\n",
       "       [ 2.31253542,  0.29266961,  0.35065687, ..., -0.85122206,\n",
       "        -0.6311377 ,  0.88418646]], shape=(1087, 18))"
      ]
     },
     "execution_count": 135,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Preprocessing of distance based(requiring scaling) models\n",
    "x_train_log_scaled= preprocessor_scale.fit_transform(x_train)\n",
    "x_train_log_scaled"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 136,
   "id": "06b07de5",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_log_scaled= preprocessor_scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 137,
   "id": "0c46724f",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Preprocessing of non-distance based(not requiring scaling) models\n",
    "x_train_log_not_scaled= preprocessor_not_scale.fit_transform(x_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 138,
   "id": "aae884dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "x_test_log_not_scaled= preprocessor_not_scale.transform(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 139,
   "id": "87eb5973",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(272, 18)\n"
     ]
    }
   ],
   "source": [
    "print(x_test_log_scaled.shape)  # Should be (n_samples, n_features), not (n_samples, n_features, 1)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1bb3b7cf",
   "metadata": {},
   "source": [
    "#### List of classification algorithms to train the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 140,
   "id": "e840337c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# A dictionary comprising of list of models\n",
    "models = {\n",
    "'Logistic Regression on original data' : LogisticRegression(),\n",
    "'Logistic Regression on transformed data' : LogisticRegression(solver= 'liblinear'),\n",
    "'Decision Tree': DecisionTreeClassifier(random_state=42,max_depth=4, criterion='gini'),\n",
    "'Random Forest': RandomForestClassifier(random_state=42),\n",
    "'K Nearest Neighbours': KNeighborsClassifier(n_neighbors=3),\n",
    "'Naive Bayes': GaussianNB(),\n",
    "'Support Vector Machine': SVC(random_state = 42)\n",
    "}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6046c59b",
   "metadata": {},
   "source": [
    "#### Evaluation of models"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 141,
   "id": "33356447",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Function to evaluate the models\n",
    "accuracy=[]\n",
    "def evaluation(model_name,model, actual, predicted):\n",
    "    accuracy.append(round(accuracy_score(actual,predicted),2))\n",
    "    print(f'\\nClassification report and parameters for {model_name}')\n",
    "    print('*'*65)\n",
    "    print(classification_report(actual,predicted))\n",
    "    print('Parameters: ',model.get_params())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b800b9df",
   "metadata": {},
   "source": [
    "#### Model creation on various algorithms"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 150,
   "id": "138b9754",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n",
      "Classification report and parameters for Logistic Regression on original data\n",
      "*****************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.67      0.74      0.70       120\n",
      "           6       0.58      0.63      0.60       103\n",
      "           7       0.60      0.48      0.54        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.62       272\n",
      "   macro avg       0.31      0.31      0.31       272\n",
      "weighted avg       0.58      0.62      0.60       272\n",
      "\n",
      "Parameters:  {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'lbfgs', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Classification report and parameters for Logistic Regression on transformed data\n",
      "*****************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.65      0.78      0.71       120\n",
      "           6       0.55      0.62      0.58       103\n",
      "           7       0.57      0.26      0.36        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.61       272\n",
      "   macro avg       0.30      0.28      0.27       272\n",
      "weighted avg       0.56      0.61      0.58       272\n",
      "\n",
      "Parameters:  {'C': 1.0, 'class_weight': None, 'dual': False, 'fit_intercept': True, 'intercept_scaling': 1, 'l1_ratio': None, 'max_iter': 100, 'multi_class': 'deprecated', 'n_jobs': None, 'penalty': 'l2', 'random_state': None, 'solver': 'liblinear', 'tol': 0.0001, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Classification report and parameters for Decision Tree\n",
      "*****************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.70      0.64      0.67       120\n",
      "           6       0.48      0.61      0.54       103\n",
      "           7       0.42      0.42      0.42        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.56       272\n",
      "   macro avg       0.27      0.28      0.27       272\n",
      "weighted avg       0.54      0.56      0.55       272\n",
      "\n",
      "Parameters:  {'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': 4, 'max_features': None, 'max_leaf_nodes': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'random_state': 42, 'splitter': 'best'}\n",
      "\n",
      "Classification report and parameters for Random Forest\n",
      "*****************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.72      0.75      0.73       120\n",
      "           6       0.57      0.67      0.62       103\n",
      "           7       0.62      0.48      0.55        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.64       272\n",
      "   macro avg       0.32      0.32      0.32       272\n",
      "weighted avg       0.61      0.64      0.62       272\n",
      "\n",
      "Parameters:  {'bootstrap': True, 'ccp_alpha': 0.0, 'class_weight': None, 'criterion': 'gini', 'max_depth': None, 'max_features': 'sqrt', 'max_leaf_nodes': None, 'max_samples': None, 'min_impurity_decrease': 0.0, 'min_samples_leaf': 1, 'min_samples_split': 2, 'min_weight_fraction_leaf': 0.0, 'monotonic_cst': None, 'n_estimators': 100, 'n_jobs': None, 'oob_score': False, 'random_state': 42, 'verbose': 0, 'warm_start': False}\n",
      "\n",
      "Classification report and parameters for K Nearest Neighbours\n",
      "*****************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.10      0.09      0.10        11\n",
      "           5       0.56      0.62      0.59       120\n",
      "           6       0.51      0.49      0.50       103\n",
      "           7       0.42      0.35      0.39        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.50       272\n",
      "   macro avg       0.27      0.26      0.26       272\n",
      "weighted avg       0.49      0.50      0.50       272\n",
      "\n",
      "Parameters:  {'algorithm': 'auto', 'leaf_size': 30, 'metric': 'minkowski', 'metric_params': None, 'n_jobs': None, 'n_neighbors': 3, 'p': 2, 'weights': 'uniform'}\n",
      "\n",
      "Classification report and parameters for Naive Bayes\n",
      "*****************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.14      0.09      0.11        11\n",
      "           5       0.69      0.70      0.69       120\n",
      "           6       0.56      0.52      0.54       103\n",
      "           7       0.49      0.71      0.58        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.59       272\n",
      "   macro avg       0.31      0.34      0.32       272\n",
      "weighted avg       0.58      0.59      0.58       272\n",
      "\n",
      "Parameters:  {'priors': None, 'var_smoothing': 1e-09}\n",
      "\n",
      "Classification report and parameters for Support Vector Machine\n",
      "*****************************************************************\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.68      0.76      0.72       120\n",
      "           6       0.54      0.73      0.62       103\n",
      "           7       0.00      0.00      0.00        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.61       272\n",
      "   macro avg       0.20      0.25      0.22       272\n",
      "weighted avg       0.51      0.61      0.55       272\n",
      "\n",
      "Parameters:  {'C': 1.0, 'break_ties': False, 'cache_size': 200, 'class_weight': None, 'coef0': 0.0, 'decision_function_shape': 'ovr', 'degree': 3, 'gamma': 'scale', 'kernel': 'rbf', 'max_iter': -1, 'probability': False, 'random_state': 42, 'shrinking': True, 'tol': 0.001, 'verbose': False}\n"
     ]
    }
   ],
   "source": [
    "distance_models = (LogisticRegression, KNeighborsClassifier, SVC)\n",
    "tree_models = (DecisionTreeClassifier, RandomForestClassifier, GaussianNB)\n",
    "\n",
    "for name, model in models.items():\n",
    "    if isinstance(model, distance_models):\n",
    "        model.fit(x_train_log_scaled, y_train)\n",
    "        y_pred = model.predict(x_test_log_scaled)\n",
    "    else:\n",
    "        # isinstance(model, tree_models):\n",
    "        model.fit(x_train_log_not_scaled, y_train)\n",
    "        y_pred = model.predict(x_test_log_not_scaled)\n",
    "    evaluation(name, model, y_test,y_pred)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "41b1dd16",
   "metadata": {},
   "source": [
    "#### Accuracy Scores can be summarized as-"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 151,
   "id": "446235fc",
   "metadata": {},
   "outputs": [],
   "source": [
    "acc_scores=pd.DataFrame(zip(models.keys(),accuracy),columns=['Models', 'Accuracy Score']).sort_values(by='Accuracy Score',ascending=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 152,
   "id": "db471e28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>Models</th>\n",
       "      <th>Accuracy Score</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>Random Forest</td>\n",
       "      <td>0.64</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>Logistic Regression on original data</td>\n",
       "      <td>0.62</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>Logistic Regression on transformed data</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>6</th>\n",
       "      <td>Support Vector Machine</td>\n",
       "      <td>0.61</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>5</th>\n",
       "      <td>Naive Bayes</td>\n",
       "      <td>0.59</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>Decision Tree</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>K Nearest Neighbours</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "</div>"
      ],
      "text/plain": [
       "                                    Models  Accuracy Score\n",
       "3                            Random Forest            0.64\n",
       "0     Logistic Regression on original data            0.62\n",
       "1  Logistic Regression on transformed data            0.61\n",
       "6                   Support Vector Machine            0.61\n",
       "5                              Naive Bayes            0.59\n",
       "2                            Decision Tree            0.56\n",
       "4                     K Nearest Neighbours            0.50"
      ]
     },
     "execution_count": 152,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "acc_scores"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "67f4a058",
   "metadata": {},
   "source": [
    "#### Inferences\n",
    "- None of the model is able to predict the categories that are not present in the dataset\n",
    "- f1-score for categories '3','4' and '8' is 0 for all the models except the one trained on Naive Bayes algorithm (support for these categories is also on the lower side)\n",
    "- Transformed data was expected to perform better on the logistic regression model, but it did not\n",
    "- The model trained on Random Forest algorithm has highest accuracy score(0.67), although SVM(0.65) and logistic regression(0.62) also have comparable values"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f60eae9f",
   "metadata": {},
   "source": [
    "#### Cross Validation- To evaluate how well the machine learning model generalizes to unseen data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 158,
   "id": "6a9b9d7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.6  0.6  0.61 0.54 0.58]\n",
      "Mean accuracy: 0.59\n"
     ]
    }
   ],
   "source": [
    "rf = RandomForestClassifier()\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(rf, x_train_log_not_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", np.round(scores,2))\n",
    "print(\"Mean accuracy:\", np.round(scores.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ddc66c6e",
   "metadata": {},
   "source": [
    "#####\n",
    "- The drop in the accuracy of the model is quite significant\n",
    "- This indicates that the issue of overfitting\n",
    "- Logistic regression is the next best model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "285288dd",
   "metadata": {},
   "source": [
    "#### Trying cross validation on logistic regression"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 159,
   "id": "b5fbb74e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.64 0.62 0.53 0.52 0.59]\n",
      "Mean accuracy: 0.58\n"
     ]
    }
   ],
   "source": [
    "lr = LogisticRegression(max_iter=1000, random_state=42)\n",
    "# Perform 5-fold cross-validation\n",
    "scores = cross_val_score(lr, x_train_log_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", np.round(scores,2))\n",
    "print(\"Mean accuracy:\", np.round(scores.mean(),2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "00f85639",
   "metadata": {},
   "source": [
    "####\n",
    "- Even for logistic regression, there is a drop in accuracy"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5b59ca78",
   "metadata": {},
   "source": [
    "#### Trying cross validation on SVM"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 160,
   "id": "827a4e04",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Cross-validation scores: [0.57 0.61 0.55 0.56 0.58]\n",
      "Mean accuracy: 0.57\n"
     ]
    }
   ],
   "source": [
    "svm= SVC()\n",
    "scores = cross_val_score(svm, x_train_log_scaled, y_train, cv=5, scoring='accuracy')\n",
    "print(\"Cross-validation scores:\", np.round(scores, 2))\n",
    "print(\"Mean accuracy:\", np.round(scores.mean(), 2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f835aafa",
   "metadata": {},
   "source": [
    "- There is a fall in accuracy level even for SVM"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "13d4738b",
   "metadata": {},
   "source": [
    "#### Hypertuning of parameters\n",
    "\n",
    "##### Trying to optimize the random forest model by hypertuning its parameters"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 161,
   "id": "a30d1a9e",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Instantiating random forest object\n",
    "rf = RandomForestClassifier(max_features='sqrt', random_state=42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 162,
   "id": "131d7ff3",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 5 folds for each of 216 candidates, totalling 1080 fits\n",
      "Best Hyperparameters:\n",
      "{'bootstrap': True, 'criterion': 'entropy', 'max_depth': None, 'max_features': None, 'max_leaf_nodes': None, 'max_samples': None}\n"
     ]
    }
   ],
   "source": [
    "# Creating a dictionary of parameters as keys and the values these parameters can take(or the ones we want to try) as values\n",
    "parameters = {\n",
    "'criterion': ['gini', 'entropy'],\n",
    "'max_depth': [None,5,10],\n",
    "'max_features':['sqrt',None],\n",
    "'bootstrap': [True, False],\n",
    "'max_samples':[None,2,4],\n",
    "'max_leaf_nodes':[None,5,10]\n",
    "}\n",
    "# Creating a GridSearchCV object\n",
    "grid_search = GridSearchCV(estimator=rf, cv=5,param_grid = parameters, verbose=1, n_jobs=1,return_train_score=True)\n",
    "\n",
    "# Fitting the training set on this object\n",
    "grid_search.fit(x_train_log_not_scaled, y_train)\n",
    "# Printing the best parameters\n",
    "print(\"Best Hyperparameters:\")\n",
    "print(grid_search.best_params_)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 164,
   "id": "9bfa1e8f",
   "metadata": {},
   "outputs": [],
   "source": [
    "best_model = grid_search.best_estimator_\n",
    "y_pred2 = best_model.predict(x_test_log_not_scaled)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af6a3123",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf.set_params(\n",
    "# bootstrap= True,\n",
    "# criterion= 'gini',\n",
    "# max_depth = None,\n",
    "# max_features = 'sqrt',\n",
    "# oob_score = True,\n",
    "# max_samples = None,\n",
    "# max_leaf_nodes = None\n",
    "# )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c5c6d36",
   "metadata": {},
   "outputs": [],
   "source": [
    "# rf.fit(x_train, y_train)\n",
    "# y_pred2= rf.predict(x_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19487741",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.70      0.73      0.72       120\n",
      "           6       0.59      0.65      0.62       103\n",
      "           7       0.61      0.55      0.58        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.63       272\n",
      "   macro avg       0.32      0.32      0.32       272\n",
      "weighted avg       0.60      0.63      0.62       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(classification_report(y_test,y_pred2))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7a0a13fe",
   "metadata": {},
   "source": [
    "No change in the accuracy of the model was observed"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ce1b2909",
   "metadata": {},
   "source": [
    "##### Trying to use robust scaler instead of standard scaler for  the logistic regression model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "17deafeb",
   "metadata": {},
   "source": [
    "## Conclusion\n",
    "\n",
    "- The model trained on Random Forest Algorithm shows the best performance amongst all the models with an accuracy of 0.67\n",
    "- The drawback of the model though is that for three categories, it shows a f1 score of 0\n",
    "- Further, there were supposed to be a total of 10 categories in the quality of wine(1-10),but only six were present in the given dataset.\n",
    "    The model fails to predict the categories absent in the dataset. Higher amount of data may have been of help in this respect"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "736bb537",
   "metadata": {},
   "outputs": [],
   "source": [
    "pipe= Pipeline(steps=[\n",
    "('preprocessing', preprocessor),\n",
    "('classifier', RandomForestClassifier(random_state=42))\n",
    "])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee431a93",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'pipe' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mNameError\u001b[39m                                 Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[73]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mpipe\u001b[49m.fit(x_train,y_train)\n",
      "\u001b[31mNameError\u001b[39m: name 'pipe' is not defined"
     ]
    }
   ],
   "source": [
    "# pipe.fit(x_train,y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cd1c1438",
   "metadata": {},
   "outputs": [],
   "source": [
    "# y_pred = pipe.predict(x_test)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d3459818",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy: 0.6286764705882353\n",
      "              precision    recall  f1-score   support\n",
      "\n",
      "           3       0.00      0.00      0.00         4\n",
      "           4       0.00      0.00      0.00        11\n",
      "           5       0.72      0.71      0.71       120\n",
      "           6       0.57      0.69      0.62       103\n",
      "           7       0.58      0.48      0.53        31\n",
      "           8       0.00      0.00      0.00         3\n",
      "\n",
      "    accuracy                           0.63       272\n",
      "   macro avg       0.31      0.31      0.31       272\n",
      "weighted avg       0.60      0.63      0.61       272\n",
      "\n"
     ]
    }
   ],
   "source": [
    "print(\"Accuracy:\", accuracy_score(y_test, y_pred))\n",
    "print(classification_report(y_test, y_pred))\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python (venv)",
   "language": "python",
   "name": "venv"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.13.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
